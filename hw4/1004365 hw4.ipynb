{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "1004365 Week 5 - AI homework - torch intro",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rUbEmuvZJxlI"
      },
      "source": [
        "# PyTorch - homework 1\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "efS07mO7J6AR"
      },
      "source": [
        "Please run the whole notebook with your code and submit the `.ipynb` file that includes your answers. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mJpzFaX0J6Zz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2cf1bce5-2a02-4577-a551-05679607295b"
      },
      "source": [
        "from termcolor import colored\n",
        "\n",
        "student_number=\"1004365\"\n",
        "student_name=\"Lee Jet Xuen\"\n",
        "\n",
        "print(colored(\"Homework by \"  + student_name + ', number: ' + student_number,'red'))"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[31mHomework by Lee Jet Xuen, number: 1004365\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-xDkwBg8LKQ_"
      },
      "source": [
        " ## Question 1 -- matrix multiplication\n",
        "\n",
        "Implement the following mathematical operation on both the CPU and GPU (use Google Colab or another cloud service if you don't have a GPU in your computer). Print:\n",
        "\n",
        "a) which type of GPU card you have and \n",
        "\n",
        "b) show the computation time for both CPU and GPU (using PyTorch). \n",
        "\n",
        "c) How much % faster is the GPU? \n",
        "\n",
        " The operation to implement is the dot product $C = B * A^T$\n",
        "\n",
        " whereby $A$ is a random matrix of size $20,000 \\times 1,000$ and $B$ is a random matrix of size $2,000 \\times 1,000$. In addition to the required information asked above:\n",
        " \n",
        " d) please also print the resulting two $C$ matrices (they should be the same btw). \n",
        " \n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BINvhm-PLKak"
      },
      "source": [
        "# implement solution here\n",
        "\n",
        "import torch\n",
        "import time\n",
        "import numpy as np\n",
        "import math\n",
        "import pandas as pd"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1a. Type of GPU"
      ],
      "metadata": {
        "id": "J0wiNB26TelW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"the type of GPU: {torch.cuda.get_device_name(0)}\")\n",
        "!nvidia-smi"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ka37c89fTjZU",
        "outputId": "ecf9faca-3393-48bd-e6e3-bed5ac081cc5"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "the type of GPU: Tesla T4\n",
            "Sun Jun 19 17:07:02 2022       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 460.32.03    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   45C    P8    13W /  70W |      3MiB / 15109MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1b. Computation time for both CPU and GPU"
      ],
      "metadata": {
        "id": "nBspXNecT1Td"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "A = torch.randn(20000, 1000, dtype=torch.float64); \n",
        "B = torch.randn(2000, 1000, dtype=torch.float64)\n",
        "A_cuda = A.cuda()\n",
        "B_cuda = B.cuda()\n",
        "\n",
        "# GPU\n",
        "timer = time.time()\n",
        "C_cuda = torch.matmul(B_cuda, torch.t(A_cuda))\n",
        "GPU_time = time.time() - timer\n",
        "print(f\"Time taken for GPU:\\t{GPU_time}s\")\n",
        "\n",
        "# CPU\n",
        "timer = time.time()\n",
        "C_cpu = torch.matmul(B, torch.t(A))\n",
        "CPU_time = time.time() - timer\n",
        "print(f\"Time taken for CPU:\\t{CPU_time}s\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5v5Zg--8T98L",
        "outputId": "99bc753a-87f9-44a3-b708-5b2675b1a72c"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Time taken for GPU:\t0.011227130889892578s\n",
            "Time taken for CPU:\t4.2156407833099365s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1c. How much % faster is the GPU?"
      ],
      "metadata": {
        "id": "elwp9kLgT-Nw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"c) GPU is {np.round(CPU_time / GPU_time)*100}% faster than CPU\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "so7XuP5GT-iz",
        "outputId": "8269d5e1-814a-4622-de52-cefac0546378"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "c) GPU is 37500.0% faster than CPU\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1d. Print the resulting C matrices"
      ],
      "metadata": {
        "id": "cZA9FcM1UCJ0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"C_GPU:\\t{C_cuda}\\n\")\n",
        "print(f\"C_CPU:\\t{C_cpu}\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A3g1f7XCUCUR",
        "outputId": "562f4853-aa7d-4822-db43-2635d1badce8"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "C_GPU:\ttensor([[ 29.4000,  30.9936,  -2.1661,  ...,  31.5115,  -5.4349, -24.7570],\n",
            "        [ 70.5538,  15.7187,  13.0485,  ..., -51.3420,  32.8407, -89.2538],\n",
            "        [ 12.8634,  31.7663,   0.3120,  ...,  -5.6911, -49.4723, -38.7836],\n",
            "        ...,\n",
            "        [-25.1265, -21.7306, -14.3646,  ...,  44.4942, -20.5908, -15.6281],\n",
            "        [ 44.0136,   6.9510,  -1.5220,  ...,   0.4727,  31.1392,  47.6024],\n",
            "        [-41.3577,  -3.5718,   9.5361,  ...,   1.1328,  36.3783, -35.7580]],\n",
            "       device='cuda:0', dtype=torch.float64)\n",
            "\n",
            "C_CPU:\ttensor([[ 29.4000,  30.9936,  -2.1661,  ...,  31.5115,  -5.4349, -24.7570],\n",
            "        [ 70.5538,  15.7187,  13.0485,  ..., -51.3420,  32.8407, -89.2538],\n",
            "        [ 12.8634,  31.7663,   0.3120,  ...,  -5.6911, -49.4723, -38.7836],\n",
            "        ...,\n",
            "        [-25.1265, -21.7306, -14.3646,  ...,  44.4942, -20.5908, -15.6281],\n",
            "        [ 44.0136,   6.9510,  -1.5220,  ...,   0.4727,  31.1392,  47.6024],\n",
            "        [-41.3577,  -3.5718,   9.5361,  ...,   1.1328,  36.3783, -35.7580]],\n",
            "       dtype=torch.float64)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LZJXmfT-yU3g"
      },
      "source": [
        "## Question 2 - grad\n",
        "\n",
        "\n",
        "Find the gradient (partial derivatives) of the function $g(w)$ below. \n",
        "\n",
        "Let  $w=[w_1,w_2]^T$\n",
        "\n",
        "Consider  $g(w)=2w_1w_2+w_2cos(w_1)$\n",
        "\n",
        "a) In PyTorch, compute:   $\\nabla g(w)$ \n",
        "\n",
        " and verify that $\\nabla g([\\pi,1])=[2,2\\pi−1]^T$ using the grad function, whereby the first position is the partial for $w_1$ and the second position is the partial for $w_2$. \n",
        "\n",
        "b) You can also write a function to manually calculate these partial derivatives! You can review your differential equations math at [here](https://www.wolframalpha.com/input/?i=derivative+y+cos%28x%29) and implement this as a second function below to verify that it comes to the same solution. \n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2a. Compute $\\nabla g(w)$ "
      ],
      "metadata": {
        "id": "fzjR7tuVgoA-"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pLjz6_LKt4sc"
      },
      "source": [
        "# write your solution here\n",
        "def g(w):\n",
        "  return 2*w[0]*w[1] + w[1]*torch.cos(w[0])"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "w = torch.tensor([math.pi,1], requires_grad=True)\n",
        "\n",
        "G = g(w)\n",
        "G.backward()\n",
        "\n",
        "print(f\"gradient with pytorch:\\t{np.round(w.grad.data.numpy(), 3)}\")\n",
        "print(f\"standard answer:\\t{[2, np.round(2*np.pi-1, 3)]}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wKD398nGg0r4",
        "outputId": "ad14edbd-7656-49a9-c6ec-20a8e69aba35"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "gradient with pytorch:\t[2.    5.283]\n",
            "standard answer:\t[2, 5.283]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2b. Calculate gradient manually"
      ],
      "metadata": {
        "id": "Z2RP9ROToueB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def g_manual(w): \n",
        "  return [-(torch.sin(w[0])-2)*w[1], 2*w[0]+torch.cos(w[0])]\n",
        "\n",
        "w = torch.tensor([np.pi, 1])\n",
        "print(f\"gradient calculated manually: {g_manual(w)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "izXDcsTtpU96",
        "outputId": "0f539e7f-1fd3-44a3-d6cb-b2f8c8783943"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "gradient calculated manually: [tensor(2.), tensor(5.2832)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rJwP6ur8LKjD"
      },
      "source": [
        "## Question 3 - dance hit song prediction\n",
        "\n",
        "Implement logistic regression in PyTorch for the following dance hit song prediction training dataset: \n",
        "https://dorax.s3.ap-south-1.amazonaws.com/herremans_hit_1030training.csv\n",
        "\n",
        " * Input variables: a number of audio features (most already standardized so don't worry about that)\n",
        " * Target variable: Topclass1030: \n",
        "   * 1 means it was a top 10 hit song; \n",
        "   * 0 means it never went above top 30 position.\n",
        "\n",
        "This dataset is derived from my paper on dance hit song prediction, for full description of features have a look at https://arxiv.org/abs/1905.08076. \n",
        "\n",
        "Print the evolution of the loss every few epochs and train the model until it converges. \n",
        " \n",
        " After training the logistic regression model, calculate the prediction accuracy on the test set: \n",
        " https://dorax.s3.ap-south-1.amazonaws.com/herremans_hit_1030test.csv\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Load data"
      ],
      "metadata": {
        "id": "zv8zlYpj4hv8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Your code here\n",
        "\n",
        "# load data\n",
        "!wget https://dorax.s3.ap-south-1.amazonaws.com/herremans_hit_1030training.csv\n",
        "!wget https://dorax.s3.ap-south-1.amazonaws.com/herremans_hit_1030test.csv\n",
        "\n",
        "train_pd = pd.read_csv('./herremans_hit_1030training.csv')\n",
        "labels = train_pd.iloc[:,-1]\n",
        "features = train_pd.loc[:, 'timesignature':'T12kurtosis']\n",
        "\n",
        "labels = torch.Tensor(labels.values).reshape(321,1)\n",
        "features = torch.Tensor(features.values)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o-iaDF1v4Wvq",
        "outputId": "acd7963f-f7dd-4f0f-9670-4e9347c01263"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-06-19 17:07:12--  https://dorax.s3.ap-south-1.amazonaws.com/herremans_hit_1030training.csv\n",
            "Resolving dorax.s3.ap-south-1.amazonaws.com (dorax.s3.ap-south-1.amazonaws.com)... 52.219.158.170\n",
            "Connecting to dorax.s3.ap-south-1.amazonaws.com (dorax.s3.ap-south-1.amazonaws.com)|52.219.158.170|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 147372 (144K) [text/csv]\n",
            "Saving to: ‘herremans_hit_1030training.csv.5’\n",
            "\n",
            "herremans_hit_1030t 100%[===================>] 143.92K   220KB/s    in 0.7s    \n",
            "\n",
            "2022-06-19 17:07:14 (220 KB/s) - ‘herremans_hit_1030training.csv.5’ saved [147372/147372]\n",
            "\n",
            "--2022-06-19 17:07:14--  https://dorax.s3.ap-south-1.amazonaws.com/herremans_hit_1030test.csv\n",
            "Resolving dorax.s3.ap-south-1.amazonaws.com (dorax.s3.ap-south-1.amazonaws.com)... 52.219.158.170\n",
            "Connecting to dorax.s3.ap-south-1.amazonaws.com (dorax.s3.ap-south-1.amazonaws.com)|52.219.158.170|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 36712 (36K) [text/csv]\n",
            "Saving to: ‘herremans_hit_1030test.csv.5’\n",
            "\n",
            "herremans_hit_1030t 100%[===================>]  35.85K   172KB/s    in 0.2s    \n",
            "\n",
            "2022-06-19 17:07:15 (172 KB/s) - ‘herremans_hit_1030test.csv.5’ saved [36712/36712]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VyRP6bl8t4Wc"
      },
      "source": [
        "# define logistic regression model\n",
        "class LogisticRegression(torch.nn.Module):\n",
        "    def __init__(self, input_dim, output_dim):\n",
        "        super(LogisticRegression, self).__init__()\n",
        "        self.linear = torch.nn.Linear(input_dim, output_dim)\n",
        "\n",
        "    def forward(self, x):\n",
        "        y_pred = torch.sigmoid(self.linear(x))\n",
        "        return y_pred"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# train model\n",
        "input_dim = features.size(1)\n",
        "output_dim = 1\n",
        "num_of_data = features.size(0)\n",
        "epochs = 100\n",
        "lr_rate = 0.1\n",
        "criterion = torch.nn.MSELoss()\n",
        "\n",
        "logreg_clf = LogisticRegression(input_dim,1)\n",
        "\n",
        "optimizer = torch.optim.SGD(logreg_clf.parameters(), lr=lr_rate)\n",
        "\n",
        "for i in range(epochs):\n",
        "    logreg_clf.train()\n",
        "    optimizer.zero_grad()\n",
        "    \n",
        "    y_hat = logreg_clf(features)\n",
        "    loss = criterion(y_hat, labels)\n",
        "\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    if i % 10 == 0:\n",
        "        print(f\"Epoch - {i}\\tLoss - {loss.item()}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BQOY9Dys5B7A",
        "outputId": "8faec1b6-62c2-40d3-e4e3-f0163899f7c3"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch - 0\tLoss - 0.280998170375824\n",
            "Epoch - 10\tLoss - 0.22378209233283997\n",
            "Epoch - 20\tLoss - 0.2133243829011917\n",
            "Epoch - 30\tLoss - 0.2068585306406021\n",
            "Epoch - 40\tLoss - 0.2020822912454605\n",
            "Epoch - 50\tLoss - 0.19834327697753906\n",
            "Epoch - 60\tLoss - 0.19531011581420898\n",
            "Epoch - 70\tLoss - 0.19278374314308167\n",
            "Epoch - 80\tLoss - 0.19063617289066315\n",
            "Epoch - 90\tLoss - 0.18878157436847687\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vw4yfGoGuChe"
      },
      "source": [
        "Run the below code to test the accuracy of your model on the training set: "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L88WmKtMt5gH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "85ea9648-9c1a-4777-bc15-f683f8d5236e"
      },
      "source": [
        "import pandas as pd \n",
        "\n",
        "test = pd.read_csv('/content/herremans_hit_1030test.csv')\n",
        "labels = test.iloc[:,-1]\n",
        "test = test.drop('Topclass1030', axis=1)\n",
        "testdata = torch.Tensor(test.values)\n",
        "testlabels = torch.Tensor(labels.values).view(-1,1)\n",
        "\n",
        "TP = 0\n",
        "TN = 0\n",
        "FN = 0\n",
        "FP = 0\n",
        "\n",
        "for i in range(0, testdata.size()[0]): \n",
        "  # print(testdata[i].size())\n",
        "  Xtest = torch.Tensor(testdata[i])\n",
        "  y_hat = logreg_clf(Xtest)\n",
        "  \n",
        "  if y_hat > 0.5:\n",
        "    prediction = 1\n",
        "  else: \n",
        "    prediction = 0\n",
        "\n",
        "  if (prediction == testlabels[i]):\n",
        "    if (prediction == 1):\n",
        "      TP += 1\n",
        "    else: \n",
        "      TN += 1\n",
        "\n",
        "  else:\n",
        "    if (prediction == 1):\n",
        "      FP += 1\n",
        "    else: \n",
        "      FN += 1\n",
        "\n",
        "print(\"True Positives: {0}, True Negatives: {1}\".format(TP, TN))\n",
        "print(\"False Positives: {0}, False Negatives: {1}\".format(FP, FN))\n",
        "rate = TP/(FN+TP)\n",
        "print(\"Class specific accuracy of correctly predicting a hit song is {0}\".format(rate))"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "True Positives: 44, True Negatives: 16\n",
            "False Positives: 13, False Negatives: 6\n",
            "Class specific accuracy of correctly predicting a hit song is 0.88\n"
          ]
        }
      ]
    }
  ]
}