{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "1004365-hw5.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rUbEmuvZJxlI"
      },
      "source": [
        "# PyTorch - homework 2: neural networks\n",
        "\n",
        "-- Prof. Dorien Herremans"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "efS07mO7J6AR"
      },
      "source": [
        "Please run the whole notebook with your code and submit the `.ipynb` file on eDimension that includes your answers [so after you run it]. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mJpzFaX0J6Zz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bc028b5c-2f66-4492-9fda-c6d63b379f3b"
      },
      "source": [
        "from termcolor import colored\n",
        "\n",
        "student_number=\"1004365\"\n",
        "student_name=\"Lee Jet Xuen\"\n",
        "\n",
        "print(colored(\"Homework by \"  + student_name + ', number: ' + student_number,'red'))"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[31mHomework by Lee Jet Xuen, number: 1004365\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-xDkwBg8LKQ_"
      },
      "source": [
        " ## Question 1 -- XOR neural network [3pts]\n",
        "\n",
        "a) Train an (at least) 2-layer neural network that can solve the XOR problem. Hint: be sure to check both this week and last week's lab. \n",
        "\n",
        "b) Check the predictions resulting from your model in the second code box below.\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# load your data\n",
        "import torch\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import Dataset, DataLoader"
      ],
      "metadata": {
        "id": "TUleAa1tNnqB"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BINvhm-PLKak"
      },
      "source": [
        "X = torch.Tensor([[0,0],[0,1], [1,0], [1,1]])\n",
        "Y = torch.Tensor([0,1,1,0]).view(-1,1)\n",
        "\n",
        "# name your model xor\n",
        "def xor():\n",
        "  return torch.nn.Sequential(torch.nn.Linear(2,2), torch.nn.Sigmoid(), torch.nn.Linear(2,1), torch.nn.Sigmoid())\n",
        "\n",
        "xor = xor()"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# define your model loss function, optimizer, etc. \n",
        "loss_func = torch.nn.BCELoss()\n",
        "lr_rate = 3e0\n",
        "momentum = 0.9\n",
        "epochs = 5000\n",
        "optimizer = torch.optim.SGD(xor.parameters(), lr=lr_rate, momentum=momentum)\n",
        "\n",
        "# train the model\n",
        "for i in range(epochs):\n",
        "    loss = loss_func(xor(X), Y)\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()"
      ],
      "metadata": {
        "id": "GItA-9eotJLf"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "51Ra1T6n2r_R",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ac039607-2b7c-45cb-a21e-284dfc2e70cc"
      },
      "source": [
        "# test your model using the following functions (make sure the output is printed and saved when you submit this notebook):\n",
        "# depending on how you defined your network you may need to slightly tweek the below prediction function\n",
        "\n",
        "test = [[0,0],[0,1],[1,1],[1,0]]\n",
        "\n",
        "for trial in test: \n",
        "  Xtest = torch.Tensor(trial)\n",
        "  y_hat = xor(Xtest)\n",
        "\n",
        "  if y_hat > 0.5:\n",
        "    prediction = 1\n",
        "  else: \n",
        "    prediction = 0\n",
        "\n",
        "  print(\"{0} xor {1} = {2}\".format(int(Xtest[0]), int(Xtest[1]), prediction))"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0 xor 0 = 0\n",
            "0 xor 1 = 1\n",
            "1 xor 1 = 0\n",
            "1 xor 0 = 1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pqIqD5ZzyUOW"
      },
      "source": [
        "## Question 2  [2pts]\n",
        "\n",
        "Imagine a neural network model for a multilabel classification task. \n",
        "\n",
        "a) Which loss function should you use?\n",
        "\n",
        "b) The resulting trained modal has a high variance error. Give 4 possible solutions to improve the model. \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hzye9G18PQ0c"
      },
      "source": [
        "```\n",
        "[your answer here, no coding required]\n",
        "\n",
        "* answer A\n",
        "Binary cross-entropy loss function. Element base decision belonging to \n",
        "a certain class should not influence the decision for another class.    \n",
        "\n",
        "* answer B\n",
        "  - Regularization\n",
        "  - Dropout\n",
        "  - Early Stopping\n",
        "  - Increase size of training set\n",
        "\n",
        "```\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FcceOSnjjSHf"
      },
      "source": [
        "## Question 3 - Improve hit classification [5pts]\n",
        "\n",
        "Remember the hit predicton dataset from last week? \n",
        "\n",
        "a) Improve the model using a multiplayer perceptron. \n",
        "\n",
        "b) Make sure to run your models on the GPU. \n",
        "\n",
        "c) Tweek the hyperparameters such as number of nodes or layers, or other. Show two possible configurations and explain which works better and very briefly explain why this may be the case. \n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# download dataset\n",
        "!wget https://dorax.s3.ap-south-1.amazonaws.com/herremans_hit_1030training.csv\n",
        "!wget https://dorax.s3.ap-south-1.amazonaws.com/herremans_hit_1030test.csv"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PHCdrE2YwXbf",
        "outputId": "242f965c-8b4b-4bf7-bd7f-ac65eaabbee8"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-06-27 10:39:19--  https://dorax.s3.ap-south-1.amazonaws.com/herremans_hit_1030training.csv\n",
            "Resolving dorax.s3.ap-south-1.amazonaws.com (dorax.s3.ap-south-1.amazonaws.com)... 52.219.160.150\n",
            "Connecting to dorax.s3.ap-south-1.amazonaws.com (dorax.s3.ap-south-1.amazonaws.com)|52.219.160.150|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 147372 (144K) [text/csv]\n",
            "Saving to: ‘herremans_hit_1030training.csv.3’\n",
            "\n",
            "herremans_hit_1030t 100%[===================>] 143.92K   229KB/s    in 0.6s    \n",
            "\n",
            "2022-06-27 10:39:21 (229 KB/s) - ‘herremans_hit_1030training.csv.3’ saved [147372/147372]\n",
            "\n",
            "--2022-06-27 10:39:21--  https://dorax.s3.ap-south-1.amazonaws.com/herremans_hit_1030test.csv\n",
            "Resolving dorax.s3.ap-south-1.amazonaws.com (dorax.s3.ap-south-1.amazonaws.com)... 52.219.160.150\n",
            "Connecting to dorax.s3.ap-south-1.amazonaws.com (dorax.s3.ap-south-1.amazonaws.com)|52.219.160.150|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 36712 (36K) [text/csv]\n",
            "Saving to: ‘herremans_hit_1030test.csv.3’\n",
            "\n",
            "herremans_hit_1030t 100%[===================>]  35.85K   172KB/s    in 0.2s    \n",
            "\n",
            "2022-06-27 10:39:22 (172 KB/s) - ‘herremans_hit_1030test.csv.3’ saved [36712/36712]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# from google.colab import drive\n",
        "# drive.mount('/content/drive')\n",
        "# %cd drive/MyDrive/50.021\\ AI/hw5/"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UHeB7k_TslND",
        "outputId": "9a1e6442-71f1-4888-e623-7e4784210e2c"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "/content/drive/MyDrive/50.021 AI/hw5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# load data\n",
        "\n",
        "device = \"cuda\"\n",
        "train_data = pd.read_csv('/content/herremans_hit_1030training.csv')\n",
        "test_data = pd.read_csv('/content/herremans_hit_1030test.csv')\n",
        "print(train_data.head(5))\n",
        "\n",
        "features = torch.FloatTensor(train_data.loc[:, train_data.columns != 'Topclass1030'].values).to(device)\n",
        "target = torch.FloatTensor(train_data['Topclass1030']).to(device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M0z8mF1ql-FO",
        "outputId": "ef3dac77-90f6-4b45-a940-aee832541252"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   timesignature  beatdifMedian  beatdifrange  beatdif80perc  beatdifvariance  \\\n",
            "0              4      -0.426354      0.159924      -0.430311        -0.201989   \n",
            "1              1      -0.425639      0.803453      -0.447282        -0.173888   \n",
            "2              4      -0.363030     -0.642618      -0.398657        -0.277881   \n",
            "3              4      -0.513649     -0.599269      -0.535959        -0.278743   \n",
            "4              4      -0.492764     -0.532997      -0.517050        -0.276868   \n",
            "\n",
            "   beatdifstdev  T1Median     T1min     T1max  T180perc  ...  T9skewness  \\\n",
            "0      0.029204 -0.054548  0.476469 -0.165555 -0.140664  ...    0.942847   \n",
            "1      0.127218 -0.068266  1.207067 -0.278461 -0.287069  ...    1.584726   \n",
            "2     -0.403862 -0.702500 -0.767956 -1.392002 -0.956162  ...   -0.256651   \n",
            "3     -0.414360 -1.525701  0.100812 -2.278600 -1.840325  ...    0.428083   \n",
            "4     -0.392195 -1.658309 -0.745546 -2.436105 -1.959553  ...    0.375415   \n",
            "\n",
            "   T9kurtosis  T10variance  T10stdev  T10skewness  T10kurtosis  T11variance  \\\n",
            "0    0.897191     0.224833  0.364433    -0.576920     0.409746     0.783243   \n",
            "1   -0.141996     0.280368  0.423894    -0.197576    -0.741571     0.418951   \n",
            "2    0.033983    -1.141890 -1.472748     0.216992    -0.737004    -1.089424   \n",
            "3   -0.485332    -0.947447 -1.144689     1.507500     0.581671    -0.637289   \n",
            "4   -0.396752    -0.371268 -0.329973    -0.066839    -0.613983    -0.625378   \n",
            "\n",
            "   T12Median  T12kurtosis  Topclass1030  \n",
            "0  -0.350775    -0.429391             1  \n",
            "1  -0.446874    -0.251202             1  \n",
            "2  -0.372608    -0.218271             1  \n",
            "3  -1.136671    -0.369950             1  \n",
            "4  -0.274704     0.892449             1  \n",
            "\n",
            "[5 rows x 50 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# code your model 1\n",
        "\n",
        "class MLP(nn.Module):\n",
        "  def __init__(self, input_size, num_classes):\n",
        "      super(MLP, self).__init__()\n",
        "      self.fc1 = nn.Linear(input_size, 32)\n",
        "      self.fc2 = nn.Linear(32, 8)\n",
        "      self.fc3 = nn.Linear(8, num_classes)\n",
        "      self.relu = nn.ReLU()\n",
        "      self.sigmoid = nn.Sigmoid()\n",
        "        \n",
        "  def forward(self, x):\n",
        "      x = self.fc1(x)\n",
        "      x = self.relu(x)\n",
        "      x = self.fc2(x)\n",
        "      x = self.relu(x)\n",
        "      x = self.fc3(x)\n",
        "      x = self.relu(x)\n",
        "      x = self.sigmoid(x)\n",
        "      return x"
      ],
      "metadata": {
        "id": "wYyPNOBFqXr0"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train(features, target, model, loss_function, optimizer, device, epochs=1000+1):\n",
        "    for epoch in range(epochs):\n",
        "        features = features.to(device)\n",
        "        target = target.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        prediction = model(features)\n",
        "        loss = loss_function(prediction, target.view(-1, 1)).to(device)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        if epoch % 50 == 0:\n",
        "            print (f\"Epoch: {epoch}, Loss: {loss}\")"
      ],
      "metadata": {
        "id": "33B9cB7etYo2"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def save(model, filepath):\n",
        "  torch.save(model.state_dict(), filepath)\n",
        "  print(f\"model saved in {filepath}\")"
      ],
      "metadata": {
        "id": "a_D8GCkjsbif"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dim_out = 1\n",
        "dim_inp = 49 \n",
        "lr_rate = 0.001\n",
        "loss_function = nn.BCELoss()\n",
        "\n",
        "model1 = MLP(dim_inp, dim_out).to(device)\n",
        "optimizer = torch.optim.Adam(model1.parameters(), lr=lr_rate)\n",
        "\n",
        "train(features, target, model1, loss_function, optimizer, device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XK5IlH85msNt",
        "outputId": "f6c17c2f-4c18-4ac8-cc88-88351e47f538"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 0, Loss: 0.684018611907959\n",
            "Epoch: 50, Loss: 0.5774528980255127\n",
            "Epoch: 100, Loss: 0.4865177869796753\n",
            "Epoch: 150, Loss: 0.3989968001842499\n",
            "Epoch: 200, Loss: 0.32910582423210144\n",
            "Epoch: 250, Loss: 0.2921326160430908\n",
            "Epoch: 300, Loss: 0.2758706212043762\n",
            "Epoch: 350, Loss: 0.2705480456352234\n",
            "Epoch: 400, Loss: 0.26831066608428955\n",
            "Epoch: 450, Loss: 0.26691052317619324\n",
            "Epoch: 500, Loss: 0.26623454689979553\n",
            "Epoch: 550, Loss: 0.26555001735687256\n",
            "Epoch: 600, Loss: 0.2651634216308594\n",
            "Epoch: 650, Loss: 0.2649206221103668\n",
            "Epoch: 700, Loss: 0.2646608352661133\n",
            "Epoch: 750, Loss: 0.26456940174102783\n",
            "Epoch: 800, Loss: 0.2643705904483795\n",
            "Epoch: 850, Loss: 0.2642989158630371\n",
            "Epoch: 900, Loss: 0.2641901671886444\n",
            "Epoch: 950, Loss: 0.2640797197818756\n",
            "Epoch: 1000, Loss: 0.26403507590293884\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# model 2\n",
        "\n",
        "class DropoutMLP(nn.Module):\n",
        "    def __init__(self, input_size, num_classes):\n",
        "        super(DropoutMLP, self).__init__()\n",
        "        self.fc1 = nn.Linear(input_size, 32)\n",
        "        self.fc2 = nn.Linear(32, 8)\n",
        "        self.fc3 = nn.Linear(8, num_classes)\n",
        "        self.relu = nn.ReLU()\n",
        "        self.sigmoid = nn.Sigmoid()\n",
        "        self.dropout = nn.Dropout(p=0.75)\n",
        "        \n",
        "    def forward(self, x):\n",
        "        x = self.fc1(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.dropout(x)\n",
        "        x = self.fc2(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.fc3(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.sigmoid(x)\n",
        "        return x\n",
        "    \n",
        "# train model 2\n",
        "\n",
        "model2 = DropoutMLP(dim_inp, dim_out).to(device)\n",
        "optimizer = torch.optim.Adam(model2.parameters(), lr=lr_rate)\n",
        "\n",
        "train(features, target, model2, loss_function, optimizer, device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tThPUWINqJIf",
        "outputId": "981b0d84-82f5-4987-9c24-ae69573182b5"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 0, Loss: 0.6931471824645996\n",
            "Epoch: 50, Loss: 0.6931471824645996\n",
            "Epoch: 100, Loss: 0.6931471824645996\n",
            "Epoch: 150, Loss: 0.6931471824645996\n",
            "Epoch: 200, Loss: 0.6931471824645996\n",
            "Epoch: 250, Loss: 0.6931471824645996\n",
            "Epoch: 300, Loss: 0.6541837453842163\n",
            "Epoch: 350, Loss: 0.5725418329238892\n",
            "Epoch: 400, Loss: 0.5523510575294495\n",
            "Epoch: 450, Loss: 0.5257366895675659\n",
            "Epoch: 500, Loss: 0.49477481842041016\n",
            "Epoch: 550, Loss: 0.47855183482170105\n",
            "Epoch: 600, Loss: 0.45215079188346863\n",
            "Epoch: 650, Loss: 0.4181925356388092\n",
            "Epoch: 700, Loss: 0.44576355814933777\n",
            "Epoch: 750, Loss: 0.4200247824192047\n",
            "Epoch: 800, Loss: 0.4148452877998352\n",
            "Epoch: 850, Loss: 0.3968169093132019\n",
            "Epoch: 900, Loss: 0.3924323320388794\n",
            "Epoch: 950, Loss: 0.3819860517978668\n",
            "Epoch: 1000, Loss: 0.36812108755111694\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "save(model1, \"model1\")\n",
        "save(model2, \"model2\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R12sf__PuN0q",
        "outputId": "28a127c2-bbd4-492d-c29c-176c30123428"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "model saved in model1\n",
            "model saved in model2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UIDPTKcFkETc"
      },
      "source": [
        "# evaluate model 1 (called model1 here)\n",
        "\n",
        "\n",
        "import pandas as pd \n",
        "\n",
        "def run_evaluation(my_model):\n",
        "\n",
        "  test = pd.read_csv('/content/herremans_hit_1030test.csv')\n",
        "  labels = test.iloc[:,-1]\n",
        "  test = test.drop('Topclass1030', axis=1)\n",
        "  testdata = torch.Tensor(test.values)\n",
        "  testlabels = torch.Tensor(labels.values).view(-1,1)\n",
        "\n",
        "  TP = 0\n",
        "  TN = 0\n",
        "  FN = 0\n",
        "  FP = 0\n",
        "\n",
        "  for i in range(0, testdata.size()[0]): \n",
        "    # print(testdata[i].size())\n",
        "    Xtest = torch.Tensor(testdata[i]).to(device)\n",
        "    y_hat = my_model(Xtest)\n",
        "    \n",
        "    if y_hat > 0.5:\n",
        "      prediction = 1\n",
        "    else: \n",
        "      prediction = 0\n",
        "\n",
        "    if (prediction == testlabels[i]):\n",
        "      if (prediction == 1):\n",
        "        TP += 1\n",
        "      else: \n",
        "        TN += 1\n",
        "\n",
        "    else:\n",
        "      if (prediction == 1):\n",
        "        FP += 1\n",
        "      else: \n",
        "        FN += 1\n",
        "\n",
        "  print(\"True Positives: {0}, True Negatives: {1}\".format(TP, TN))\n",
        "  print(\"False Positives: {0}, False Negatives: {1}\".format(FP, FN))\n",
        "  rate = TP/(FN+TP)\n",
        "  print(\"Class specific accuracy of correctly predicting a hit song is {0}\".format(rate))"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### to read the model file"
      ],
      "metadata": {
        "id": "sns7QQRXunkc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# device = \"cuda\"\n",
        "# model1 = MLP(dim_inp, dim_out).to(device)\n",
        "# model1.load_state_dict(torch.load(\"model1\"))\n",
        "\n",
        "# model2 = DropoutMLP(dim_inp, dim_out).to(device)\n",
        "# model2.load_state_dict(torch.load(\"model2\"))"
      ],
      "metadata": {
        "id": "4X5TtdOLunMB"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xghPDDNmkHn2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6dd53e06-54c7-44ec-d7cf-a67e3a5f4394"
      },
      "source": [
        "# evaluate on model 1\n",
        "model1.eval()\n",
        "run_evaluation(model1)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "True Positives: 45, True Negatives: 10\n",
            "False Positives: 19, False Negatives: 5\n",
            "Class specific accuracy of correctly predicting a hit song is 0.9\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wAIifiHJkHyW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "77d65bb5-6de2-4535-d39c-7015d7f8d780"
      },
      "source": [
        "# evaluate model 2 (called model2 here)\n",
        "model2.eval()\n",
        "run_evaluation(model2)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "True Positives: 47, True Negatives: 10\n",
            "False Positives: 19, False Negatives: 3\n",
            "Class specific accuracy of correctly predicting a hit song is 0.94\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QPsxbT0KkGs1"
      },
      "source": [
        "Which works better and why do you think this may be (very briefly)? \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6GzjI77HkSwH"
      },
      "source": [
        "**[your answer here, also please summarise the differences between your two models]**\n",
        "\n",
        "Both models are 3 layers logistic regression classifier, with the same optimizer and loss function. However, `model2` has a **dropout layer** after the first fully connected layer\n",
        "\n",
        "The model 2 performs better than model 1 in terms of class specific accuracy, and predicted more true positives than model 1. The dropout layer force the model to not rely on any single particular node when training as it will be turned off randomly. This helps in prevent overfitting."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hh5O8qS_khug"
      },
      "source": [
        "Additionally, submit your results [here](https://forms.gle/NtJJEE7Wm5ZRM3Je7) for 'Class specific accuracy of correctly predicting a hit song' and see if you got the best performance of the class! Good luck!"
      ]
    }
  ]
}